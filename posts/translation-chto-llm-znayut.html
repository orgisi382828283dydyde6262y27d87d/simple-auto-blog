<!DOCTYPE html>
<html lang="en">
    <head>
        <title>[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают</title>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="/assets/css/main.css?v=1.0"/>
                <title>[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают</title>
        <meta name="description" content="Развитие больших языковых моделей (Large Language Model, LLM) привело к смене парадигмы в сфере обработки естественного языка (Natural Language Processing, NLP). LLM, обученные на огромных объёмах текста, взятого из интернета, могут осваивать выполнение новых задач, задействуя механизмы контекстного обучения. Это означает, что NLP‑специалисты, «натаскивая» такие модели на решение определённых задач, не занимаются обновлением их параметров. Вместо этого специалисты пишут для LLM промпты, демонстрирующие желаемое поведение моделей и содержащие инструкции или некоторое количество готовых примеров. Эти промпты передают моделям в виде входного контекста (потому это и называют «контекстным обучением»), а модели используют информацию из промптов для формирования ответов на похожие вопросы. Читать далее%"/>
        <meta name="robots" content="index, follow, max-snippet:-1, max-video-preview:-1, max-image-preview:large"/>
        <link rel="canonical" href="https://habrb.eu.org/posts/translation-chto-llm-znayut/" />
        <meta property="og:locale" content="en_US" />
        <meta property="og:type" content="website" />
        <meta property="og:title" content="[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают" />
        <meta property="og:description" content="Развитие больших языковых моделей (Large Language Model, LLM) привело к смене парадигмы в сфере обработки естественного языка (Natural Language Processing, NLP). LLM, обученные на огромных объёмах текста, взятого из интернета, могут осваивать выполнение новых задач, задействуя механизмы контекстного обучения. Это означает, что NLP‑специалисты, «натаскивая» такие модели на решение определённых задач, не занимаются обновлением их параметров. Вместо этого специалисты пишут для LLM промпты, демонстрирующие желаемое поведение моделей и содержащие инструкции или некоторое количество готовых примеров. Эти промпты передают моделям в виде входного контекста (потому это и называют «контекстным обучением»), а модели используют информацию из промптов для формирования ответов на похожие вопросы. Читать далее%" />
        <meta property="og:url" content="https://habrb.eu.org/" />
        <meta property="og:site_name" content="[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают" />
        <meta property="og:updated_time" content="2022-09-24T00:38:58+00:00" />
        <meta property="og:image" content="/assets/images/post-preview.png" />
        <meta property="og:image:secure_url" content="/assets/images/post-preview.png" />
        <meta property="og:image:width" content="1200" />
        <meta property="og:image:height" content="630" />
        <meta property="og:image:alt" content="habr backup blog" />
        <meta property="og:image:type" content="image/png" />
        <meta property="article:published_time" content="2022-01-26T02:58:02+00:00" />
        <meta property="article:modified_time" content="2022-09-24T00:38:58+00:00" />
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:title" content="[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают" />
        <meta name="twitter:description" content="Развитие больших языковых моделей (Large Language Model, LLM) привело к смене парадигмы в сфере обработки естественного языка (Natural Language Processing, NLP). LLM, обученные на огромных объёмах текста, взятого из интернета, могут осваивать выполнение новых задач, задействуя механизмы контекстного обучения. Это означает, что NLP‑специалисты, «натаскивая» такие модели на решение определённых задач, не занимаются обновлением их параметров. Вместо этого специалисты пишут для LLM промпты, демонстрирующие желаемое поведение моделей и содержащие инструкции или некоторое количество готовых примеров. Эти промпты передают моделям в виде входного контекста (потому это и называют «контекстным обучением»), а модели используют информацию из промптов для формирования ответов на похожие вопросы. Читать далее%" />
        <meta name="twitter:image" content="/assets/images/post-preview.png" />
        <meta name="twitter:label1" content="Written by" />
        <meta name="twitter:data1" content="habrb" />
        <meta name="twitter:label2" content="Time to read" />
        <meta name="twitter:data2" content="11 minutes" />
        <script type="application/ld+json" class="rank-math-schema">{"@context":"https://schema.org","@graph":[{"@type":["Habr","Backup"],"@id":"https://habrb.eu.org/#organization","name":"[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают","url":"https://habrb.eu.org","logo":{"@type":"ImageObject","@id":"https://habrb.eu.org/#logo","url":"https://habrb.eu.org/wp-content/uploads/2022/02/TheDentalLogo.png","contentUrl":"https://habrb.eu.org/wp-content/uploads/2022/02/TheDentalLogo.png","caption":"[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают","inLanguage":"ru-RU","width":"160","height":"90"},"openingHours":["Monday,Tuesday,Wednesday,Thursday,Friday,Saturday,Sunday 09:00-17:00"],"image":{"@id":"https://habrb.eu.org/#logo"}},{"@type":"WebSite","@id":"https://habrb.eu.org/#website","url":"https://habrb.eu.org","name":"[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают","publisher":{"@id":"https://habrb.eu.org/#organization"},"inLanguage":"ru-RU","potentialAction":{"@type":"SearchAction","target":"https://habrb.eu.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://habrb.eu.org/wp-content/uploads/2022/07/Vision.svg","url":"https://habrb.eu.org/wp-content/uploads/2022/07/Vision.svg","width":"200","height":"200","inLanguage":"ru-RU"},{"@type":"WebPage","@id":"https://habrb.eu.org/#webpage","url":"https://habrb.eu.org/","name":"[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают","datePublished":"2022-01-26T02:58:02+00:00","dateModified":"2022-09-24T00:38:58+00:00","about":{"@id":"https://habrb.eu.org/#organization"},"isPartOf":{"@id":"https://habrb.eu.org/#website"},"primaryImageOfPage":{"@id":"https://habrb.eu.org/wp-content/uploads/2022/07/Vision.svg"},"inLanguage":"ru-RU"},{"@type":"Person","@id":"https://habrb.eu.org/author/habrb/","name":"habrb","url":"https://habrb.eu.org/author/habrb/","image":{"@type":"ImageObject","@id":"/assets/images/post-preview.png","url":"/assets/images/post-preview.png","caption":"habrb","inLanguage":"ru-RU"},"sameAs":["https://habrb.eu.org"],"worksFor":{"@id":"https://habrb.eu.org/#organization"}},{"@type":"Article","headline":"[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают","keywords":"Wunder Fund corporate blog,Artificial Intelligence,Learning languages,Natural Language Processing,Искусственный интеллект,Большие языковые модели,LLM","datePublished":"2022-01-26T02:58:02+00:00","dateModified":"2022-09-24T00:38:58+00:00","author":{"@id":"https://habrb.eu.org/author/habrb/"},"publisher":{"@id":"https://habrb.eu.org/#organization"},"description":"Развитие больших языковых моделей (Large Language Model, LLM) привело к смене парадигмы в сфере обработки естественного языка (Natural Language Processing, NLP). LLM, обученные на огромных объёмах текста, взятого из интернета, могут осваивать выполнение новых задач, задействуя механизмы контекстного обучения. Это означает, что NLP‑специалисты, «натаскивая» такие модели на решение определённых задач, не занимаются обновлением их параметров. Вместо этого специалисты пишут для LLM промпты, демонстрирующие желаемое поведение моделей и содержащие инструкции или некоторое количество готовых примеров. Эти промпты передают моделям в виде входного контекста (потому это и называют «контекстным обучением»), а модели используют информацию из промптов для формирования ответов на похожие вопросы. Читать далее%","name":"[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают","@id":"https://habrb.eu.org/#richSnippet","isPartOf":{"@id":"https://habrb.eu.org/#webpage"},"image":{"@id":"https://habrb.eu.org/wp-content/uploads/2022/07/Vision.svg"},"inLanguage":"ru-RU","mainEntityOfPage":{"@id":"https://habrb.eu.org/#webpage"}}]}</script>
        <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
        <link rel="manifest" href="/site.webmanifest">
    </head>
    <body>
        <nav class="menu">
            <h2>Habr Backup Blog</h2>
        </nav>
        <script type="text/javascript" src="https://g.Cash-Ads.com/banner/?code=u6a9hGg6UOFh8sfEZG3Fe08gcTxcFxi1%2FMqoPhTNu8c%3D"></script>
        <main class="post-main">
            <h1 class="title">[Translation] Что LLM знают о лингвистике? Это зависит от того, какие вопросы им задают</h1>
            <div class="keywords">
                <div class="keyword">Wunder Fund corporate blog</div><div class="keyword">Artificial Intelligence</div><div class="keyword">Learning languages</div><div class="keyword">Natural Language Processing</div><div class="keyword">Iskusstvennyj intellekt</div><div class="keyword">Bolyshie yazykovye modeli</div><div class="keyword">LLM</div><div class="keyword">Wunder Fund corporate blog</div><div class="keyword">Artificial Intelligence</div><div class="keyword">Learning languages</div><div class="keyword">Natural Language Processing</div><div class="keyword">Искусственный интеллект</div><div class="keyword">Большие языковые модели</div><div class="keyword">LLM</div>
            </div>
            <div class="content">
<p>Развитие больших языковых моделей (Large Language Model, LLM) привело к смене парадигмы в сфере обработки естественного языка (Natural Language Processing, NLP). LLM, обученные на огромных объёмах текста, взятого из интернета, могут осваивать выполнение новых задач, задействуя механизмы контекстного обучения. Это означает, что NLP‑специалисты, «натаскивая» такие модели на решение определённых задач, не занимаются обновлением их параметров. Вместо этого специалисты пишут для LLM промпты, демонстрирующие желаемое поведение моделей и содержащие инструкции или некоторое количество готовых примеров. Эти промпты передают моделям в виде входного контекста (потому это и называют «контекстным обучением»), а модели используют информацию из промптов для формирования ответов на похожие вопросы.</p>
<p></p> <a href="https://habr.com/en/articles/754414/?utm_source=habrahabr&amp;utm_medium=rss&amp;utm_campaign=754414#habracut" class="btn-read">Читать далее</a>
</div>
            <div class="btn-box">
                <a href="/backup/?path=translation-chto-llm-znayut">Show backup</a>
            </div>
        </main>
        <!-- Yandex.Metrika counter -->
        <script type="text/javascript" >
           (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
           var z = null;m[i].l=1*new Date();
           for (var j = 0; j < document.scripts.length; j++) {if (document.scripts[j].src === r) { return; }}
           k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
           (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

           ym(90037404, "init", {
                clickmap:true,
                trackLinks:true,
                accurateTrackBounce:true,
                webvisor:true
           });
        </script>
        <noscript><div><img src="https://mc.yandex.ru/watch/90037404" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
        <!-- /Yandex.Metrika counter -->
    </body>
</html>
